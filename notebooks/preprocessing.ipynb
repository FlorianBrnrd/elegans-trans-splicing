{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dad380f5",
   "metadata": {},
   "source": [
    "# Pre-processing read alignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0149cc16",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "This notebook compiles the scripts that are used as part of the pre-processing step of our analysis in order to produce a data table (referred in other notebooks as **dataset**) used accross all downstream analysis. \n",
    "\n",
    "It is organized in three main parts:<br>\n",
    "\n",
    "- **1. Parse genomic and transcriptomic alignments:**<br>\n",
    "Scripts used for extracting alignments features such as start & end positions of each read, reference gene and isoform on which the read is mapped, etc. Also features a script for correcting genomic start & end positions based on transcriptomic alignments. \n",
    "\n",
    "- **2. Splice Leader (SL) search:**<br>\n",
    "Method used for identifying splice leader sequences in transcriptomic reads (see **Figure 2 and Figure 3 notebooks**)\n",
    "\n",
    "- **3. Hairpin search:**<br>\n",
    "Method used for identifying hairpin structure (SL mimic) in non-SL reads (see **Figure 4 and Figure 5 notebooks**)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e800507",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-31T17:34:03.500891Z",
     "iopub.status.busy": "2022-01-31T17:34:03.488799Z",
     "iopub.status.idle": "2022-01-31T17:34:03.725465Z",
     "shell.execute_reply": "2022-01-31T17:34:03.715320Z",
     "shell.execute_reply.started": "2022-01-31T17:34:03.497774Z"
    }
   },
   "source": [
    "---\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9038853",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6677a7b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T21:23:45.742321Z",
     "iopub.status.busy": "2022-04-13T21:23:45.741977Z",
     "iopub.status.idle": "2022-04-13T21:23:48.340733Z",
     "shell.execute_reply": "2022-04-13T21:23:48.340000Z",
     "shell.execute_reply.started": "2022-04-13T21:23:45.742279Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pysam\n",
    "import re\n",
    "from re import search\n",
    "import json\n",
    "import pyranges as pr\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import parasail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0973778",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2331089",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-31T17:38:21.576699Z",
     "iopub.status.busy": "2022-01-31T17:38:21.575283Z",
     "iopub.status.idle": "2022-01-31T17:38:21.587175Z",
     "shell.execute_reply": "2022-01-31T17:38:21.585003Z",
     "shell.execute_reply.started": "2022-01-31T17:38:21.576636Z"
    }
   },
   "source": [
    "# 1. Parse genomic and transcriptomic alignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0841215",
   "metadata": {},
   "source": [
    "## 1.a. Parsing genomic alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4edea99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T21:23:48.344343Z",
     "iopub.status.busy": "2022-04-13T21:23:48.343773Z",
     "iopub.status.idle": "2022-04-13T21:23:48.355633Z",
     "shell.execute_reply": "2022-04-13T21:23:48.354644Z",
     "shell.execute_reply.started": "2022-04-13T21:23:48.344275Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract features from genomic alignments (read name, chromosome, genomic start & end positions)\n",
    "\n",
    "def genomic_stats(input_file, output_file):\n",
    "\n",
    "    name = []\n",
    "    start = []\n",
    "    end = []\n",
    "    chrom = []\n",
    "\n",
    "    alignment = pysam.AlignmentFile(input_file, 'rb')\n",
    "\n",
    "    for read in alignment:\n",
    "\n",
    "        # Only take into account primary reads\n",
    "        if not read.is_supplementary and not read.is_secondary and not read.is_unmapped and read.seq is not None:\n",
    "\n",
    "            name.append(read.query_name)\n",
    "            chrom.append(alignment.get_reference_name(read.reference_id))\n",
    "            start.append(read.reference_start+1) # 0-based coordinates - see doc\n",
    "            end.append(read.reference_end) # Points to one past last coordinate (so 1-based ?)\n",
    "\n",
    "    # Build dataframe with lists\n",
    "    table = pd.DataFrame(dict(read=name, chromosome=chrom, genomic_start=start, genomic_end=end,))\n",
    "\n",
    "    # Save dataframe as a .tsv file\n",
    "    table.to_csv(output_file, sep='\\t', index=None)\n",
    "    \n",
    "    alignment.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ed9a975",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T21:23:48.357188Z",
     "iopub.status.busy": "2022-04-13T21:23:48.356887Z",
     "iopub.status.idle": "2022-04-13T21:31:35.082462Z",
     "shell.execute_reply": "2022-04-13T21:31:35.074302Z",
     "shell.execute_reply.started": "2022-04-13T21:23:48.357150Z"
    }
   },
   "outputs": [],
   "source": [
    "runs = ['SSP_1', 'SSP_2', 'SSP_3', 'SSP_4', 'SSP_5', 'SSP_6', 'SL1_1', 'NP_1', 'NP_2', 'NP_3', 'NP_4', 'NP_5']\n",
    "\n",
    "for ID in runs:\n",
    "\n",
    "    input_file = f'/Volumes/elegans/rna_sequencing/{ID}/{ID}-genome_sorted.bam'\n",
    "    output_name = f'{ID}-genomic_stats.tsv'\n",
    "    \n",
    "    # run script\n",
    "    genomic_stats(input_file, output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cadf19",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befeee20",
   "metadata": {},
   "source": [
    "## 1.b. Parsing transcriptomic alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d27fafa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T21:31:35.093868Z",
     "iopub.status.busy": "2022-04-13T21:31:35.093417Z",
     "iopub.status.idle": "2022-04-13T21:31:35.108493Z",
     "shell.execute_reply": "2022-04-13T21:31:35.107445Z",
     "shell.execute_reply.started": "2022-04-13T21:31:35.093817Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert isoform name into gene name\n",
    "# ex: MTCE.35.1 -> MTCE.35\n",
    "\n",
    "def isoform_to_gene(isoform):\n",
    "    \n",
    "    match = re.search(r\"\\w+.\\d+\", isoform)\n",
    "\n",
    "    if match is not None:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b67d6a31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T21:31:35.110279Z",
     "iopub.status.busy": "2022-04-13T21:31:35.109931Z",
     "iopub.status.idle": "2022-04-13T21:31:35.135322Z",
     "shell.execute_reply": "2022-04-13T21:31:35.133900Z",
     "shell.execute_reply.started": "2022-04-13T21:31:35.110249Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract features from transcriptomic alignments (read name, isoform, gene, transcriptomic start & end positions, etc.)\n",
    "\n",
    "def transcriptomic_stats(input_file, output_file):\n",
    "\n",
    "    name = []\n",
    "    isoform = []\n",
    "    start = []\n",
    "    end = []\n",
    "    orientation = []\n",
    "    softclip = []\n",
    "\n",
    "    transcriptome = pysam.AlignmentFile(input_file, 'rb')\n",
    "\n",
    "    for read in transcriptome:\n",
    "\n",
    "        # Only take into account primary reads\n",
    "        if not read.is_unmapped and not read.is_secondary and not read.is_supplementary and read.seq is not None:\n",
    "\n",
    "            name.append(read.query_name)\n",
    "            isoform.append(transcriptome.get_reference_name(read.reference_id))\n",
    "            start.append(read.reference_start+1)\n",
    "            end.append(read.reference_end)\n",
    "\n",
    "            # Find read orientation\n",
    "            if read.is_reverse:\n",
    "                orientation.append('antisense')\n",
    "            else:\n",
    "                orientation.append('sense')\n",
    "\n",
    "            # Find soft-clip length\n",
    "            cigar = read.cigarstring\n",
    "            sc = search(r'^(\\d*)S', cigar) if cigar is not None else None\n",
    "            if sc:\n",
    "                length = int(sc.group(1))\n",
    "            else:\n",
    "                length = 0\n",
    "\n",
    "            softclip.append(1) if length > 80 else softclip.append(0)\n",
    "\n",
    "\n",
    "    # Generate dataframe\n",
    "    dataframe = pd.DataFrame(dict(read=name, isoform=isoform, transcriptomic_start=start, transcriptomic_end=end, softclip=softclip, read_orientation=orientation))\n",
    "\n",
    "    # Find gene_ID with isoform value\n",
    "    dataframe['gene'] = dataframe['isoform'].apply(isoform_to_gene)\n",
    "\n",
    "    # Set columns order\n",
    "    dataframe = dataframe[['read', 'gene', 'isoform', 'transcriptomic_start', 'transcriptomic_end', 'read_orientation', 'softclip']]\n",
    "\n",
    "    # Save dataframe\n",
    "    dataframe.to_csv(output_file, sep='\\t', index=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4937834c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T21:31:35.137235Z",
     "iopub.status.busy": "2022-04-13T21:31:35.136763Z",
     "iopub.status.idle": "2022-04-13T21:43:59.055809Z",
     "shell.execute_reply": "2022-04-13T21:43:59.048595Z",
     "shell.execute_reply.started": "2022-04-13T21:31:35.137196Z"
    }
   },
   "outputs": [],
   "source": [
    "runs = ['SSP_1', 'SSP_2', 'SSP_3', 'SSP_4', 'SSP_5', 'SSP_6', 'SL1_1', 'NP_1', 'NP_2', 'NP_3', 'NP_4', 'NP_5']\n",
    "\n",
    "for ID in runs:\n",
    "    \n",
    "    input_file = f'/Volumes/elegans/rna_sequencing/{ID}/{ID}-transcriptome_sorted.bam'\n",
    "    output_file = f'{ID}-transcriptome_stats.tsv'\n",
    "\n",
    "    # run script\n",
    "    transcriptomic_stats(input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c812f9",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ca17f7",
   "metadata": {},
   "source": [
    "## 1.c. Create summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4bba635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T21:43:59.067397Z",
     "iopub.status.busy": "2022-04-13T21:43:59.067031Z",
     "iopub.status.idle": "2022-04-13T21:45:20.338993Z",
     "shell.execute_reply": "2022-04-13T21:45:20.336947Z",
     "shell.execute_reply.started": "2022-04-13T21:43:59.067350Z"
    }
   },
   "outputs": [],
   "source": [
    "# set empty list to store intermediary dataframes\n",
    "dflist = []\n",
    "\n",
    "# loop over runs\n",
    "runs = ['SSP_1', 'SSP_2', 'SSP_3', 'SSP_4', 'SSP_5', 'SSP_6', 'SL1_1', 'NP_1', 'NP_2', 'NP_3', 'NP_4', 'NP_5']\n",
    "\n",
    "for ID in runs:\n",
    "\n",
    "    genome = f'{ID}-genomic_stats.tsv'\n",
    "    transcriptome = f'{ID}-transcriptome_stats.tsv'\n",
    "\n",
    "    # open genomic stats\n",
    "    genome_stats = pd.read_csv(genome, sep='\\t')\n",
    "    genome_stats = genome_stats.set_index('read')\n",
    "\n",
    "    # open transcriptomics stats\n",
    "    transcriptome_stats = pd.read_csv(transcriptome, sep='\\t')\n",
    "    transcriptome_stats = transcriptome_stats.set_index('read')\n",
    "\n",
    "    # concat tables together\n",
    "    final = pd.concat([genome_stats, transcriptome_stats], join='outer', axis=1)\n",
    "    \n",
    "    # only keep reads that are mapped against both genome and transcriptome files\n",
    "    final = final.loc[(final['genomic_start'].notnull()) & (final['transcriptomic_start'].notnull())]\n",
    "\n",
    "    final.index.name = 'read'\n",
    "    final = final.reset_index()\n",
    "\n",
    "    final['run'] = ID\n",
    "\n",
    "    final = final[['read', 'gene', 'isoform', 'chromosome', 'genomic_start', 'genomic_end', \n",
    "                   'transcriptomic_start', 'transcriptomic_end', 'read_orientation', 'softclip', 'run']]\n",
    "\n",
    "    dflist.append(final)\n",
    "\n",
    "stats = pd.concat(dflist, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acb6b93f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T21:45:20.356959Z",
     "iopub.status.busy": "2022-04-13T21:45:20.356576Z",
     "iopub.status.idle": "2022-04-13T21:52:02.314653Z",
     "shell.execute_reply": "2022-04-13T21:52:02.310136Z",
     "shell.execute_reply.started": "2022-04-13T21:45:20.356915Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build dictionnary of gene orientation \n",
    "strand = pd.read_csv('/Volumes/elegans/rna_sequencing/ref/gene&strand.tsv', sep='\\t')\n",
    "strands = {x['gene']: x['strand'] for idx, x in strand.iterrows()}\n",
    "\n",
    "# Set Start and end correctly\n",
    "stats['start'] = stats.apply(lambda x: x['genomic_start'] if strands[x['gene']] == '+' else x['genomic_end'], axis=1)\n",
    "stats['genomic_start'] = stats['start']\n",
    "\n",
    "stats['end'] = stats.apply(lambda x: x['genomic_end'] if strands[x['gene']] == '+' else x['genomic_start'], axis=1)\n",
    "stats['genomic_end'] = stats['end']\n",
    "\n",
    "# reorder and drop 'start' and 'end' columns\n",
    "stats = stats[['read', 'gene', 'isoform', 'chromosome',\n",
    "               'genomic_start', 'genomic_end', 'transcriptomic_start', 'transcriptomic_end',\n",
    "                'read_orientation', 'softclip', 'run']]\n",
    "\n",
    "# save result\n",
    "stats.to_csv(f'dataset.tsv', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "262157c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T21:52:02.325203Z",
     "iopub.status.busy": "2022-04-13T21:52:02.324858Z",
     "iopub.status.idle": "2022-04-13T21:53:32.998750Z",
     "shell.execute_reply": "2022-04-13T21:53:32.997676Z",
     "shell.execute_reply.started": "2022-04-13T21:52:02.325167Z"
    }
   },
   "outputs": [],
   "source": [
    "## TO REMOVE\n",
    "stats.to_csv(f'dataset.tsv', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b211ac",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a95caac",
   "metadata": {},
   "source": [
    "## 1.d. Correction of genomic coordinates based on transcriptome alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9cfe4c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T21:53:33.001819Z",
     "iopub.status.busy": "2022-04-13T21:53:33.001521Z",
     "iopub.status.idle": "2022-04-13T21:53:54.920437Z",
     "shell.execute_reply": "2022-04-13T21:53:54.919341Z",
     "shell.execute_reply.started": "2022-04-13T21:53:33.001773Z"
    }
   },
   "outputs": [],
   "source": [
    "# Open GTF file as PyRanges-object\n",
    "gtf = pr.read_gtf('/Volumes/elegans/rna_sequencing/ref/c_elegans.PRJNA13758.WS270.canonical_geneset.gtf')\n",
    "gtf = gtf.df\n",
    "\n",
    "strand = gtf.loc[gtf['Feature'] == 'transcript'].set_index('transcript_id')['Strand'].to_dict()\n",
    "\n",
    "gtf = gtf.loc[~gtf['exon_id'].isna()][['exon_id', 'Start', 'End']].set_index('exon_id')[['Start', 'End']].to_dict()\n",
    "\n",
    "# Open transcriptome_relative_coordinates\n",
    "with open('/Volumes/elegans/rna_sequencing/ref/transcript_exons.json', 'r') as dico:\n",
    "    exonics_positions = json.loads(dico.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e8e8e05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T21:53:54.923261Z",
     "iopub.status.busy": "2022-04-13T21:53:54.923010Z",
     "iopub.status.idle": "2022-04-13T21:53:54.931899Z",
     "shell.execute_reply": "2022-04-13T21:53:54.930693Z",
     "shell.execute_reply.started": "2022-04-13T21:53:54.923235Z"
    }
   },
   "outputs": [],
   "source": [
    "# This script converts a transcriptomic position into a genomic position based on a given isoform\n",
    "def transcriptome_based_correction(transcript, transcriptome_position):\n",
    "    \n",
    "    exons = exonics_positions[transcript]\n",
    "\n",
    "    for exon, i in exons.items():\n",
    "\n",
    "        if i[0] <= transcriptome_position <= i[1]:\n",
    "\n",
    "            delta = transcriptome_position - i[0]\n",
    "\n",
    "            if strand[transcript] == '+':\n",
    "                exon_start = gtf['Start'][f'{transcript}.e{exon}']\n",
    "                genomic_position = exon_start + delta\n",
    "            else:\n",
    "                exon_start = gtf['End'][f'{transcript}.e{exon}']\n",
    "                genomic_position = exon_start - delta\n",
    "\n",
    "            return genomic_position\n",
    "\n",
    "        else:\n",
    "            if int(exon) < len(exons):\n",
    "                continue\n",
    "            else:\n",
    "                return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bb461d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T21:53:54.933973Z",
     "iopub.status.busy": "2022-04-13T21:53:54.933473Z",
     "iopub.status.idle": "2022-04-13T21:53:54.945810Z",
     "shell.execute_reply": "2022-04-13T21:53:54.944781Z",
     "shell.execute_reply.started": "2022-04-13T21:53:54.933930Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transcriptomic alignment positions are used to refine genomic positions\n",
    "def correct_genomic_position(input_file):\n",
    "\n",
    "    table = pd.read_csv(input_file, sep='\\t')\n",
    "    \n",
    "    # correct start and end positons\n",
    "    table['corrected_genomic_start'] = table.apply(lambda x: transcriptome_based_correction(x['isoform'], x['transcriptomic_start']), axis=1)\n",
    "    table['corrected_genomic_end'] = table.apply(lambda x: transcriptome_based_correction(x['isoform'], x['transcriptomic_end']), axis=1)\n",
    "    \n",
    "    # useful ?\n",
    "    table = table.loc[table['gene'].notnull()]\n",
    "    \n",
    "    # reorder columns\n",
    "    final = table[['read', 'gene', 'isoform', 'chromosome', 'genomic_start', 'genomic_end',\n",
    "                   'corrected_genomic_start', 'corrected_genomic_end',\n",
    "                   'read_orientation', 'softclip', 'run']]\n",
    "    \n",
    "    # return table with corrected positions\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66a65342",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T21:53:54.949077Z",
     "iopub.status.busy": "2022-04-13T21:53:54.948592Z",
     "iopub.status.idle": "2022-04-13T22:02:43.655223Z",
     "shell.execute_reply": "2022-04-13T22:02:43.652046Z",
     "shell.execute_reply.started": "2022-04-13T21:53:54.949041Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run script\n",
    "corrected_dataset = correct_genomic_position(input_file=f'dataset.tsv')\n",
    "\n",
    "# clean up columns type\n",
    "col_types = {'read':object, 'gene':object, 'isoform':object, 'chromosome':object,\n",
    "             'genomic_start':float,'genomic_end':float,'corrected_genomic_start':float,'corrected_genomic_end':float,\n",
    "             'read_orientation':object,'softclip':int,'run':object}\n",
    "\n",
    "corrected_dataset = corrected_dataset.astype(col_types)\n",
    "\n",
    "# save table\n",
    "corrected_dataset.to_csv('dataset.tsv', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeecc42",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59614138",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-31T18:41:29.263946Z",
     "iopub.status.busy": "2022-01-31T18:41:29.260207Z",
     "iopub.status.idle": "2022-01-31T18:41:29.291939Z",
     "shell.execute_reply": "2022-01-31T18:41:29.288436Z",
     "shell.execute_reply.started": "2022-01-31T18:41:29.263805Z"
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38ba2f1",
   "metadata": {},
   "source": [
    "# 2. Splice Leader (SL) search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac825c7b",
   "metadata": {},
   "source": [
    "This section of the notebook corresponds to the code used for searching splice leader (SL) sequences in the different reads obtained from the sequencing of *C. elegans* transcriptome.\n",
    "\n",
    "It is composed of three sub-sections:<br>\n",
    "**a.** Extraction of the last 100bp of the 5' soft-clip sequence.<br>\n",
    "**b.** Definition of the algorithm used for identifying a SL sequence.<br>\n",
    "**c.** Inclusion of the SL search result to the dataset table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e85933e",
   "metadata": {},
   "source": [
    "## 2.a. Extracting 5' soft-clip sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f87a3cff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T22:02:43.663431Z",
     "iopub.status.busy": "2022-04-13T22:02:43.662983Z",
     "iopub.status.idle": "2022-04-13T22:02:43.686231Z",
     "shell.execute_reply": "2022-04-13T22:02:43.684945Z",
     "shell.execute_reply.started": "2022-04-13T22:02:43.663367Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract last 100bp of 5' soft-clip sequence and first 2bp of primary alignment from transcriptomic alignments\n",
    "# \n",
    "\n",
    "def five_prime_softclip(input_file, output_file):\n",
    "\n",
    "    alignments = pysam.AlignmentFile(input_file, 'rb')\n",
    "\n",
    "    with open(output_file, 'w+') as fasta:\n",
    "\n",
    "        for read in alignments:\n",
    "\n",
    "            if not read.is_secondary and not read.is_supplementary and not read.is_unmapped and read.seq is not None:\n",
    "\n",
    "                name = read.query_name\n",
    "                # equivalent to soft-clip length\n",
    "                start = read.query_alignment_start\n",
    "\n",
    "                # softclip longer than 100bp\n",
    "                if start > 100:\n",
    "                    seq = read.seq[start - 100:start + 2]\n",
    "\n",
    "                # softclip smaller than 100bp\n",
    "                elif start <= 100:\n",
    "                    seq = read.seq[:start + 2]\n",
    "\n",
    "                fasta.write(f'>{name}\\n{seq}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b49b2165",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T22:02:43.689981Z",
     "iopub.status.busy": "2022-04-13T22:02:43.689704Z",
     "iopub.status.idle": "2022-04-13T22:16:59.142458Z",
     "shell.execute_reply": "2022-04-13T22:16:59.134168Z",
     "shell.execute_reply.started": "2022-04-13T22:02:43.689950Z"
    }
   },
   "outputs": [],
   "source": [
    "runs = ['SSP_1', 'SSP_2', 'SSP_3', 'SSP_4', 'SSP_5', 'SSP_6', 'SL1_1', 'NP_1', 'NP_2', 'NP_3', 'NP_4', 'NP_5']\n",
    "\n",
    "for ID in runs:\n",
    "    \n",
    "    file = f'/Volumes/elegans/rna_sequencing/{ID}/{ID}-transcriptome_sorted.bam'\n",
    "    out = f'/Volumes/elegans/rna_sequencing/{ID}/{ID}-five_prime_softclip.fasta'\n",
    "    \n",
    "    five_prime_softclip(input_file=file, output_file=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89c2ce7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-05T09:06:57.197274Z",
     "iopub.status.busy": "2021-10-05T09:06:57.196988Z",
     "iopub.status.idle": "2021-10-05T09:06:57.202826Z",
     "shell.execute_reply": "2021-10-05T09:06:57.201398Z",
     "shell.execute_reply.started": "2021-10-05T09:06:57.197244Z"
    }
   },
   "source": [
    "## 2.b. SL Search algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93f1b001",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T22:16:59.163255Z",
     "iopub.status.busy": "2022-04-13T22:16:59.162720Z",
     "iopub.status.idle": "2022-04-13T22:16:59.199352Z",
     "shell.execute_reply": "2022-04-13T22:16:59.197511Z",
     "shell.execute_reply.started": "2022-04-13T22:16:59.163183Z"
    }
   },
   "outputs": [],
   "source": [
    "DEFAULT_ALIGN_PARAMS = {'match': 1,\n",
    "                        'mismatch': -1,\n",
    "                        'gap_open': 2,    # penalty to create a gap\n",
    "                        'gap_extend': 1}  # penalty to extend a gap (must have created before)\n",
    "\n",
    "\n",
    "# Performs pairwise local alignment\n",
    "def semi_global_alignment(reference, query, params=DEFAULT_ALIGN_PARAMS):\n",
    "\n",
    "    subs_mat = parasail.matrix_create(\"ACGT\", params['match'], params['mismatch'])\n",
    "    alignment = parasail.sg_trace_striped_32(reference, query, params['gap_open'], params['gap_extend'], subs_mat)\n",
    "\n",
    "    return alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a145eee3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T22:16:59.202229Z",
     "iopub.status.busy": "2022-04-13T22:16:59.201847Z",
     "iopub.status.idle": "2022-04-13T22:16:59.298540Z",
     "shell.execute_reply": "2022-04-13T22:16:59.297034Z",
     "shell.execute_reply.started": "2022-04-13T22:16:59.202186Z"
    }
   },
   "outputs": [],
   "source": [
    "# For each read, all known SL1 and SL2 sequences are matched against their 5' soft-clip sequence.\n",
    "# A match is returned if the alignment score is higher or equal to 70% (sensitivity parameter) of the sequence length\n",
    "# ex: a 10bp sequence will be accepted if the returned score is higher of equal at 7.\n",
    "\n",
    "# If no match is returned, the evaluated SL sequence is shortened (on the 5' side) and the match is performed again.\n",
    "# ex: sequence 'AAATTGTGTGTGT' returned no match, we then search 'ATTGTGTGTGT'\n",
    "\n",
    "# The process is repeated until we reach a minimal sequence of 7bp. If no match is found, the SL is considered not found.\n",
    "# If various SL sequences return the same score they are equally accepted\n",
    "\n",
    "def search_splice_leaders(input_file, output_file, sensitivity=0.7):\n",
    "\n",
    "    seq_file = open('/Volumes/elegans/rna_sequencing/ref/SL_sequences.fasta')\n",
    "    SPLICELEADERS = {record.id: str(record.seq) for record in SeqIO.parse(seq_file, \"fasta\")}\n",
    "\n",
    "    reads = {}\n",
    "\n",
    "    for record in SeqIO.parse(input_file, \"fasta\"):\n",
    "\n",
    "        ref = len(record.seq)\n",
    "\n",
    "        aln_scores = {}\n",
    "        position = {}\n",
    "        distance = {}\n",
    "\n",
    "        for sl_name in SPLICELEADERS:\n",
    "\n",
    "            sl_seq = SPLICELEADERS[sl_name]\n",
    "\n",
    "            sl_length = len(sl_seq)\n",
    "\n",
    "            aln = semi_global_alignment(str(record.seq), sl_seq)\n",
    "            score = aln.score\n",
    "\n",
    "            if score < sl_length * sensitivity:\n",
    "\n",
    "                for pos in reversed(range(7, sl_length, 1)):\n",
    "\n",
    "                    aln = semi_global_alignment(str(record.seq), sl_seq[-pos:])\n",
    "                    score = aln.score\n",
    "\n",
    "                    if score < sensitivity * pos:\n",
    "                        continue\n",
    "                    else:\n",
    "                        aln_scores[sl_name] = score\n",
    "                        position[sl_name] = pos\n",
    "                        distance[sl_name] = ref - (int(aln.end_query) + 1)\n",
    "                        break\n",
    "            else:\n",
    "                aln_scores[sl_name] = score\n",
    "                position[sl_name] = sl_length\n",
    "                distance[sl_name] = ref - (int(aln.end_query) + 1)\n",
    "\n",
    "        if len(aln_scores) > 0:\n",
    "\n",
    "            #### Get best % match SL\n",
    "            top_score = max(aln_scores.values())\n",
    "            best_matches = [sl for sl, value in aln_scores.items() if value == top_score]\n",
    "\n",
    "            if len(best_matches) == 1:\n",
    "\n",
    "                sl_found = best_matches[0]\n",
    "                distance = distance[sl_found]\n",
    "                reads[record.id] = (sl_found, top_score, distance)\n",
    "\n",
    "            else:\n",
    "\n",
    "                distance = [dist for sl, dist in distance.items() if sl in best_matches]\n",
    "                small_dist = min(distance)\n",
    "                ix = [n for n, dist in enumerate(distance) if dist == small_dist]\n",
    "                \n",
    "                closest_match = [sl for n, sl in enumerate(best_matches) if n in ix]\n",
    "\n",
    "                sl_found = ' / '.join(closest_match)\n",
    "\n",
    "                reads[record.id] = (sl_found, top_score, small_dist)\n",
    "\n",
    "\n",
    "    final = pd.DataFrame.from_dict(reads, orient='index')\n",
    "    final.columns = ['SL','score','distance_to_start']\n",
    "    final.index.name = 'read'\n",
    "    final.to_csv(output_file, sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5130f877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T22:16:59.303348Z",
     "iopub.status.busy": "2022-04-13T22:16:59.302219Z",
     "iopub.status.idle": "2022-04-14T07:52:58.913981Z",
     "shell.execute_reply": "2022-04-14T07:52:58.907226Z",
     "shell.execute_reply.started": "2022-04-13T22:16:59.303288Z"
    }
   },
   "outputs": [],
   "source": [
    "runs = ['SSP_1', 'SSP_2', 'SSP_3', 'SSP_4', 'SSP_5', 'SSP_6', 'SL1_1', 'NP_1', 'NP_2', 'NP_3', 'NP_4', 'NP_5']\n",
    "\n",
    "for ID in runs:\n",
    "\n",
    "    file= f'/Volumes/elegans/rna_sequencing/{ID}/{ID}-five_prime_softclip.fasta'\n",
    "    out= f'{ID}-SL_search.tsv'\n",
    "    \n",
    "    # run script\n",
    "    search_splice_leaders(input_file=file, output_file=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f95e9c",
   "metadata": {},
   "source": [
    "## 2.c. Processing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4c0cb15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T07:52:58.921282Z",
     "iopub.status.busy": "2022-04-14T07:52:58.920919Z",
     "iopub.status.idle": "2022-04-14T07:53:09.786906Z",
     "shell.execute_reply": "2022-04-14T07:53:09.785782Z",
     "shell.execute_reply.started": "2022-04-14T07:52:58.921236Z"
    }
   },
   "outputs": [],
   "source": [
    "# set new dataframe\n",
    "sl_result = pd.DataFrame()\n",
    "\n",
    "runs = ['SSP_1', 'SSP_2', 'SSP_3', 'SSP_4', 'SSP_5', 'SSP_6', 'SL1_1', 'NP_1', 'NP_2', 'NP_3', 'NP_4', 'NP_5']\n",
    "\n",
    "for ID in runs:\n",
    "    \n",
    "    # open SL search result as dataframe\n",
    "    df = pd.read_csv(f'{ID}-SL_search.tsv', sep='\\t')\n",
    "    \n",
    "    # append to new dataframe\n",
    "    sl_result = pd.concat([sl_result, df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c06519e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T07:53:09.789328Z",
     "iopub.status.busy": "2022-04-14T07:53:09.789068Z",
     "iopub.status.idle": "2022-04-14T07:53:46.818333Z",
     "shell.execute_reply": "2022-04-14T07:53:46.811048Z",
     "shell.execute_reply.started": "2022-04-14T07:53:09.789298Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge SL result dataframe with dataset\n",
    "dataset_SL = corrected_dataset.merge(sl_result, on='read',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26cc946f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T07:53:46.830093Z",
     "iopub.status.busy": "2022-04-14T07:53:46.829695Z",
     "iopub.status.idle": "2022-04-14T07:53:46.852864Z",
     "shell.execute_reply": "2022-04-14T07:53:46.851062Z",
     "shell.execute_reply.started": "2022-04-14T07:53:46.830025Z"
    }
   },
   "outputs": [],
   "source": [
    "# Returns a binary result (FOUND / NOT FOUND) based on the detection of a SL with high confidence or not\n",
    "# Robust SL are defined based on their alignment score (score of 10 or higher)\n",
    "# Or based on how close they are found to the start of the alignment\n",
    "\n",
    "def robust_SL(SL, score, dist):\n",
    "    \n",
    "    if SL:\n",
    "    \n",
    "        if score > 9 or dist < 3:\n",
    "            return 'FOUND'\n",
    "        else:\n",
    "            return 'NOT FOUND'\n",
    "    else:\n",
    "        return 'NOT FOUND'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f355f86b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T07:53:46.859223Z",
     "iopub.status.busy": "2022-04-14T07:53:46.858549Z",
     "iopub.status.idle": "2022-04-14T07:57:40.757364Z",
     "shell.execute_reply": "2022-04-14T07:57:40.755857Z",
     "shell.execute_reply.started": "2022-04-14T07:53:46.859117Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find robust SL match\n",
    "dataset_SL['ROBUST_SL'] = dataset_SL.apply(lambda x: robust_SL(SL=x['SL'], score=x['score'], dist=x['distance_to_start']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "194053de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T07:57:40.762009Z",
     "iopub.status.busy": "2022-04-14T07:57:40.761603Z",
     "iopub.status.idle": "2022-04-14T07:57:40.769180Z",
     "shell.execute_reply": "2022-04-14T07:57:40.768099Z",
     "shell.execute_reply.started": "2022-04-14T07:57:40.761974Z"
    }
   },
   "outputs": [],
   "source": [
    "def robust_variant(SL, score, dist):\n",
    "\n",
    "    if SL:\n",
    "    \n",
    "        # any match which scored 10 or plus\n",
    "        if score > 9 :\n",
    "            return 'FOUND'\n",
    "        \n",
    "        # matchs which score 8 or 9 IF immediatily near the ATG\n",
    "        else:\n",
    "            \n",
    "            if score > 7 and dist < 3:\n",
    "                return 'FOUND'\n",
    "            \n",
    "            else:\n",
    "                return 'NOT FOUND'\n",
    "    \n",
    "    else:\n",
    "        return 'NOT FOUND'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06ca0f59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T07:57:40.772117Z",
     "iopub.status.busy": "2022-04-14T07:57:40.771640Z",
     "iopub.status.idle": "2022-04-14T08:01:19.190873Z",
     "shell.execute_reply": "2022-04-14T08:01:19.189492Z",
     "shell.execute_reply.started": "2022-04-14T07:57:40.772084Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find robust SL match\n",
    "dataset_SL['ROBUST_VARIANT'] = dataset_SL.apply(lambda x: robust_variant(SL=x['SL'], score=x['score'], dist=x['distance_to_start']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "886c37a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T08:01:19.196561Z",
     "iopub.status.busy": "2022-04-14T08:01:19.195700Z",
     "iopub.status.idle": "2022-04-14T08:03:21.186061Z",
     "shell.execute_reply": "2022-04-14T08:03:21.184953Z",
     "shell.execute_reply.started": "2022-04-14T08:01:19.196507Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save result\n",
    "dataset_SL.to_csv('dataset_+SL.tsv', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5541b093",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c701d9",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8b1b06",
   "metadata": {},
   "source": [
    "# 3. Hairpin Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a922d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-03T10:14:35.906837Z",
     "iopub.status.idle": "2022-02-03T10:14:35.907244Z",
     "shell.execute_reply": "2022-02-03T10:14:35.907097Z"
    }
   },
   "source": [
    "This section of the notebook corresponds to the code used for searching hairpin sequences (referred as **hairpin mimic**) sequences in non-SL reads.\n",
    "\n",
    "\n",
    "**a.** Definition of the algorithm used for identifying hairpin mimics.<br>\n",
    "**b.** Processing result of the search algorithm and integration to the dataset table.<br>\n",
    "**c.** Determination of SL and hairpin mimic events in each gene.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d3df41",
   "metadata": {},
   "source": [
    "## 3.a. Hairpin mimic search algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e456ebcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T08:03:21.187580Z",
     "iopub.status.busy": "2022-04-14T08:03:21.187287Z",
     "iopub.status.idle": "2022-04-14T08:03:25.145876Z",
     "shell.execute_reply": "2022-04-14T08:03:25.145018Z",
     "shell.execute_reply.started": "2022-04-14T08:03:21.187541Z"
    }
   },
   "outputs": [],
   "source": [
    "# store alignment files in dictionnary for easier manipulation\n",
    "run_files = {}\n",
    "\n",
    "runs = ['SSP_1', 'SSP_2', 'SSP_3', 'SSP_4', 'SSP_5', 'SSP_6', 'SL1_1', 'NP_1', 'NP_2', 'NP_3', 'NP_4', 'NP_5']\n",
    "\n",
    "for ID in runs:\n",
    "    \n",
    "    file = f'/Volumes/elegans/rna_sequencing/{ID}/{ID}-transcriptome_sorted.bam'\n",
    "    run_files[ID] = pysam.AlignmentFile(file,'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d2d6094",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T08:03:25.150033Z",
     "iopub.status.busy": "2022-04-14T08:03:25.149748Z",
     "iopub.status.idle": "2022-04-14T08:03:25.158064Z",
     "shell.execute_reply": "2022-04-14T08:03:25.156847Z",
     "shell.execute_reply.started": "2022-04-14T08:03:25.150004Z"
    }
   },
   "outputs": [],
   "source": [
    "DEFAULT_ALIGN_PARAMS = {'match': 1,\n",
    "                        'mismatch': 0,\n",
    "                        'gap_open': 2,    # penalty to create a gap\n",
    "                        'gap_extend': 1}  # penalty to extend a gap (must have created before)\n",
    "\n",
    "\n",
    "def semi_global_alignment(reference, query, params=DEFAULT_ALIGN_PARAMS):\n",
    "\n",
    "    subs_mat = parasail.matrix_create(\"ACGT\", params['match'], params['mismatch'])\n",
    "    alignment = parasail.sg_trace_striped_32(reference, query, params['gap_open'], params['gap_extend'], subs_mat)\n",
    "\n",
    "    return alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e49d12d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T08:03:25.162182Z",
     "iopub.status.busy": "2022-04-14T08:03:25.161814Z",
     "iopub.status.idle": "2022-04-14T08:21:47.064691Z",
     "shell.execute_reply": "2022-04-14T08:21:47.059078Z",
     "shell.execute_reply.started": "2022-04-14T08:03:25.162090Z"
    }
   },
   "outputs": [],
   "source": [
    "# write result directly to a .tsv file as each read is processed\n",
    "with open('hairpin_search.tsv', 'w+') as out:\n",
    "    \n",
    "    # set columns names\n",
    "    out.write('read\\tHAIRPIN_SCORE\\tHAIRPIN_SEARCH\\n')\n",
    "    \n",
    "    # open transcriptomic alignment file\n",
    "    for ID in runs:\n",
    "        \n",
    "        # open corresponding alignment file\n",
    "        alignments = run_files[ID]\n",
    "        \n",
    "        \n",
    "        # loop over alignments in file\n",
    "        for read in alignments:\n",
    "            \n",
    "            # only evaluate primary alignments\n",
    "            if not read.is_unmapped and not read.is_secondary and not read.is_supplementary and read.seq is not None:\n",
    "                \n",
    "                name = read.query_name\n",
    "                \n",
    "                if read.query_qualities is not None and read.is_reverse:\n",
    "                    \n",
    "                    start = read.query_alignment_start\n",
    "                    \n",
    "                    # if read have too short end the search is not performed\n",
    "                    if start > 20:\n",
    "                    \n",
    "                        # softclip end \n",
    "                        softclip_region = str(Seq(read.seq[start-13:start+2]).reverse_complement())\n",
    "\n",
    "                        # start of aligned sequence\n",
    "                        aligned_region = str(read.seq[start+2:start+42])\n",
    "\n",
    "                        # perform semi-global alignment and retrieve score\n",
    "                        aln = semi_global_alignment(aligned_region, softclip_region)\n",
    "                        score = aln.score\n",
    "\n",
    "                        # if there is a match (at least score of 12 for a sequence of 15bp)\n",
    "                        if score >= 12:\n",
    "                            out.write(f'{name}\\t{score}\\tFOUND\\n')\n",
    " \n",
    "                        else:\n",
    "                            out.write(f'{name}\\t{score}\\tNOT FOUND\\n')\n",
    "\n",
    "                     # if no search was performed\n",
    "                    else:\n",
    "                        out.write(f'{name}\\t{0}\\tNOT FOUND\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f81f6a1",
   "metadata": {},
   "source": [
    "## 3.b. Processing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6455d6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T08:21:47.135143Z",
     "iopub.status.busy": "2022-04-14T08:21:47.134174Z",
     "iopub.status.idle": "2022-04-14T08:25:09.573449Z",
     "shell.execute_reply": "2022-04-14T08:25:09.557611Z",
     "shell.execute_reply.started": "2022-04-14T08:21:47.135090Z"
    }
   },
   "outputs": [],
   "source": [
    "# open hairpin search table\n",
    "hairpin_result = pd.read_csv('hairpin_search.tsv', sep='\\t')\n",
    "\n",
    "# Merge SL result dataframe with dataset\n",
    "dataset_SL_hairpin = dataset_SL.merge(hairpin_result, on='read', how='left')\n",
    "\n",
    "# save\n",
    "dataset_SL_hairpin.to_csv('dataset_+SL_+hairpin.tsv', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeb3667",
   "metadata": {},
   "source": [
    "## 3.c. Determination of SL and hairpin mimic events in each detected gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21358e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-14T08:25:09.595880Z",
     "iopub.status.busy": "2022-04-14T08:25:09.594842Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute stats per gene per start positions (%SL / %hairpin / %unidentified)\n",
    "\n",
    "_GENE = []\n",
    "_POS = []\n",
    "_TOTAL = []\n",
    "_SUBTOTAL = []\n",
    "_SL = []\n",
    "_SLpercent = []\n",
    "_HAIRPIN = []\n",
    "_HAIRPINpercent = []\n",
    "_UNIDENTIFIED = []\n",
    "_UNIDENTIFIEDpercent = []\n",
    "\n",
    "_SL1 = []\n",
    "_SL2 = []\n",
    "_RATIO = []\n",
    "\n",
    "for (gene, position), reads in dataset_SL_hairpin.groupby(['gene','corrected_genomic_start']):\n",
    "\n",
    "    # gene\n",
    "    _GENE.append(gene)\n",
    "    \n",
    "    # position\n",
    "    _POS.append(int(position))\n",
    "    \n",
    "    # Total of reads at a given position\n",
    "    total = len(reads)\n",
    "    _TOTAL.append(total)\n",
    "    \n",
    "    # Sense reads from SL1_1 experiment are not used for counting SL1/SL2/Hairpin percentages\n",
    "    reads = pd.concat([reads[reads['run'] != 'SL1_1'], \n",
    "                       reads[(reads['run'] == 'SL1_1') & (reads['read_orientation'] == 'antisense')]])\n",
    "    \n",
    "    # count nb of reads used for measuring percentages\n",
    "    percent_tot = len(reads)\n",
    "    _SUBTOTAL.append(percent_tot)\n",
    "    \n",
    "    if percent_tot > 0:\n",
    "    \n",
    "        #### count SL robust (no matter the variant)\n",
    "        sl = reads[reads['ROBUST_SL'] == 'FOUND']\n",
    "        _SL.append(len(sl))\n",
    "        sl_percent = round(len(sl) / percent_tot * 100,  2)\n",
    "        _SLpercent.append(sl_percent)\n",
    "        \n",
    "        \n",
    "        # get details on SL1 and SL2 -> subgroup of ROBUST SL for which we have a ROBUST VARIANT\n",
    "        variants = reads[reads['ROBUST_VARIANT'] == 'FOUND']\n",
    "        # count SL1\n",
    "        _sl1 = len(variants[variants['SL'].str.contains('SL1')])\n",
    "        _SL1.append(_sl1)\n",
    "        # count SL2 \n",
    "        _sl2 = len(variants[~variants['SL'].str.contains('SL1')])\n",
    "        _SL2.append(_sl2)\n",
    "        # measure SL2/SL1 ratio\n",
    "        if _sl1+_sl2 > 0:\n",
    "            ratio = _sl2/(_sl1+_sl2)\n",
    "        else:\n",
    "            ratio = None\n",
    "        _RATIO.append(ratio)\n",
    "        \n",
    "\n",
    "        #### Hairpin positive reads\n",
    "        sl_reads = list(sl['read'])\n",
    "        hairpin = reads[(reads['read_orientation'] == 'antisense') & (reads['read'].isin(sl_reads) == False) & (reads['HAIRPIN_SEARCH']=='FOUND')]\n",
    "        _HAIRPIN.append(len(hairpin))\n",
    "        hairpin_percent = round(len(hairpin) / percent_tot * 100, 2)\n",
    "        _HAIRPINpercent.append(hairpin_percent)\n",
    "\n",
    "        #### Unidentified reads\n",
    "        hairpin_reads = list(hairpin['read'])\n",
    "        unidentified = reads[reads['read'].isin(sl_reads+hairpin_reads) == False]\n",
    "        _UNIDENTIFIED.append(len(unidentified))\n",
    "        unidentified_percent = round(len(unidentified) / percent_tot * 100, 2)\n",
    "        _UNIDENTIFIEDpercent.append(unidentified_percent)\n",
    "    \n",
    "    else:\n",
    "        _SLpercent.append(0)\n",
    "        _SL.append(0)\n",
    "\n",
    "        _SL1.append(0)\n",
    "        _SL2.append(0)\n",
    "        _RATIO.append(None)\n",
    "        \n",
    "        _HAIRPIN.append(0)\n",
    "        _HAIRPINpercent.append(0)\n",
    "        \n",
    "        _UNIDENTIFIED.append(0)\n",
    "        _UNIDENTIFIEDpercent.append(100)\n",
    "\n",
    "    \n",
    "    \n",
    "# create dataframe\n",
    "result = pd.DataFrame(dict(gene=_GENE, position=_POS, total=_TOTAL, evaluated=_SUBTOTAL, SL=_SL, SL1=_SL1, SL2=_SL2, hairpin=_HAIRPIN, unidentified=_UNIDENTIFIED,\n",
    "                           SLpercent=_SLpercent, hairpinpercent=_HAIRPINpercent, unidentifiedpercent=_UNIDENTIFIEDpercent, SL2_ratio=_RATIO))\n",
    "\n",
    "result.columns = ['gene', 'position', 'total', 'evaluated', 'SL', 'SL1', 'SL2', 'hairpin', 'unidentified', '%SL', '%hairpin', '%unidentified', 'SL2_ratio']\n",
    "\n",
    "result = result.sort_values(['gene','position'])\n",
    "\n",
    "# save table\n",
    "result.to_csv('SL_&_mimic_positions.tsv', sep='\\t', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
